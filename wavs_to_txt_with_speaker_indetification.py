import whisper
import os
import torch
import sys
import time
from dotenv import load_dotenv
from tqdm import tqdm
from datetime import timedelta
import traceback
import torchaudio
from resemblyzer import VoiceEncoder, preprocess_wav
from sklearn.cluster import DBSCAN
import numpy as np

# –ó–∞–≥—Ä—É–∑–∫–∞ .env –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
load_dotenv()

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è CUDA
device = "cuda" if torch.cuda.is_available() else "cpu"

if device == "cuda":
    print("üöÄ –ù–∞–π–¥–µ–Ω–∞ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–∞! –†–∞–±–æ—Ç–∞–µ–º –Ω–∞ CUDA.")
    model_name = "medium"
else:
    print("üñ•Ô∏è CUDA –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –†–∞–±–æ—Ç–∞–µ–º –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ (CPU).")
    model_name = "small"

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper
print(f"üì¶ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper: {model_name}")
model = whisper.load_model(model_name).to(device)

# –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å —Ñ–∞–π–ª–∞–º–∏
folder_path = "./wavs"
results_folder = os.path.join(folder_path, "results")
os.makedirs(results_folder, exist_ok=True)

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –ª–æ–≥-—Ñ–∞–π–ª–∞
log_file = open(os.path.join(results_folder, "log.txt"), "w", encoding="utf-8")
original_stdout = sys.stdout
sys.stdout = log_file

# –ó–∞–ø—É—Å–∫ —Ç–∞–π–º–µ—Ä–∞
start_time = time.time()

# –î–æ–ø—É—Å—Ç–∏–º—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
extensions = (".wav", ".mp3", ".m4a", ".flac", ".ogg", ".mp4", ".avi", ".mov", ".mkv")
media_files = [f for f in os.listdir(folder_path) if f.lower().endswith(extensions)]

def cluster_speakers_dbscan(embeddings):
    embeddings = np.array(embeddings)

    clustering = DBSCAN(eps=0.5, min_samples=5, metric="euclidean").fit(embeddings)
    labels = clustering.labels_

    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ {n_clusters} —Å–ø–∏–∫–µ—Ä–æ–≤ (—á–µ—Ä–µ–∑ DBSCAN)")

    return labels

def format_timestamp_srt(seconds):
    td = timedelta(seconds=seconds)
    total_seconds = int(td.total_seconds())
    millis = int((seconds - total_seconds) * 1000)
    hours = total_seconds // 3600
    minutes = (total_seconds % 3600) // 60
    secs = total_seconds % 60
    return f"{hours:02}:{minutes:02}:{secs:02},{millis:03}"

# –õ–æ–≥–∏
successfully_processed = []
failed_files = []

encoder = VoiceEncoder()

for filename in tqdm(media_files, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤", ncols=100):
    try:
        file_path = os.path.join(folder_path, filename)
        print(f"\nüöÄ –†–∞–±–æ—Ç–∞–µ–º —Å —Ñ–∞–π–ª–æ–º: {filename}")

        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Whisper
        result = model.transcribe(file_path, word_timestamps=True, language="ru")

        detected_language = result.get("language", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
        print(f"üåç –û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —è–∑—ã–∫: {detected_language}")

        # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
        wav, sr = torchaudio.load(file_path)
        wav = wav.mean(dim=0).numpy()  # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ –º–æ–Ω–æ
        wav = preprocess_wav(wav, source_sr=sr)

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        frames = encoder.embed_utterance(wav, return_partials=True)[1]

        # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ DBSCAN
        speaker_labels = cluster_speakers_dbscan(frames)

        final_text = ""
        srt_content = ""
        srt_counter = 1

        for i, segment in enumerate(result['segments']):
            start_srt = format_timestamp_srt(segment['start'])
            end_srt = format_timestamp_srt(segment['end'])
            text = segment['text'].strip()

            # –ó–∞—â–∏—Ç–∞: –µ—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ç–æ–∫ –º–µ–Ω—å—à–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            speaker_idx = speaker_labels[min(i, len(speaker_labels) - 1)]
            speaker = f"–°–ø–∏–∫–µ—Ä {speaker_idx}" if speaker_idx != -1 else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å–ø–∏–∫–µ—Ä"

            # –î–ª—è txt
            final_text += f"[{start_srt} - {end_srt}] {speaker}: {text}\n"

            # –î–ª—è srt
            srt_content += f"{srt_counter}\n{start_srt} --> {end_srt}\n{speaker}: {text}\n\n"
            srt_counter += 1

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º .txt
        output_txt = os.path.splitext(filename)[0] + ".txt"
        with open(os.path.join(results_folder, output_txt), "w", encoding="utf-8") as f:
            f.write(final_text)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º .srt
        output_srt = os.path.splitext(filename)[0] + ".srt"
        with open(os.path.join(results_folder, output_srt), "w", encoding="utf-8") as f:
            f.write(srt_content)

        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ñ–∞–π–ª—ã: {output_txt}, {output_srt}")
        successfully_processed.append(filename)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {filename}: {e}")
        traceback.print_exc()
        failed_files.append((filename, str(e)))

# –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
print("\nüéØ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(successfully_processed)}")
for f in successfully_processed:
    print(f" - {f}")

if failed_files:
    print(f"\n‚ùå –û—à–∏–±–∫–∏ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–æ–≤: {len(failed_files)}")
    for f, err in failed_files:
        print(f" - {f}: {err}")

# –¢–∞–π–º–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏
end_time = time.time()
elapsed_time = end_time - start_time
minutes = int(elapsed_time // 60)
seconds = int(elapsed_time % 60)
print(f"\nüïí –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {minutes} –º–∏–Ω {seconds} —Å–µ–∫")

# –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
sys.stdout = original_stdout
log_file.close()

print("\nüìÑ –õ–æ–≥ —Ä–∞–±–æ—Ç—ã —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ —Ñ–∞–π–ª: results/log.txt")
print("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
